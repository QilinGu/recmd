package com.xhui.recmd.core.service;

import com.xhui.recmd.core.hao.*;
import com.xhui.recmd.core.redis.rao.IpToIpDisRao;
import com.xhui.recmd.core.union.*;
import com.xhui.recmd.spark.services.HdfsResultCarryer;
import com.xhui.recmd.spark.utils.HbaseApi;
import org.apache.commons.collections.ListUtils;
import org.apache.commons.httpclient.util.DateUtil;
import org.apache.hadoop.hbase.protobuf.generated.ClientProtos;
import org.apache.log4j.Logger;

import javax.swing.plaf.ListUI;
import java.util.*;

/**
 * Created by littlehui on 2016/10/18.
 */
public class RecmdCoreService {

    String uri = "hdfs://10.5.117.109:9000/";   //hdfs 地址

    private static Integer EXPIRE_SECONDS = 60 * 60;

    String resultUri = "hdfs://10.5.117.109:9000/spark/job/result/20160919.result";

    private static final String DEFAULT_VISIT_TABLE = "visitCount";

    private static final String CLASS_TABLE = "classifier";

    private InvidualInterestPointHao invidualInterestPointHao = new InvidualInterestPointHao();

    private ClassifierHao classifierHao = new ClassifierHao();

    private ClassifierCorePointHao classifierCorePointHao = new ClassifierCorePointHao();

    private IpToIpDisHao ipToIpDisHao = new IpToIpDisHao();

    private IpToIpDisRao ipToIpDisRao = IpToIpDisRao.getInstance();

    private RecmdResultHao recmdResultHao = new RecmdResultHao();

    Logger logger = Logger.getLogger(RecmdCoreService.class);

    /**
     * 第一步：从hbase表里查找出 ip对应兴趣数据 封装成 List<IndividualInterestPoint>
     * 第二步：给Kmeans聚类。聚类结果存入 hbase 的 classifier
     * 第三部：获取聚类后的数据，计算出每个IP应该推荐的列表，暴露出接口
     */
    HbaseApi hbaseApi = new HbaseApi("10.5.117.151,10.5.117.152");

    public void doKMeansCluser(List<IndividualCommonPoint> individualInterestPoints) {
        Long startMills = System.currentTimeMillis();
        logger.info("doKMeansCluser 开始：时间：" + DateUtil.formatDate(new Date(startMills)));
        int k = (int) Math.sqrt(individualInterestPoints.size());
        KMeansCluster kMeansCluster = new KMeansCluster(individualInterestPoints, k);
        List<IndividualCommonPoint>[] results = kMeansCluster.cluster();
        ArraySet<IndividualCommonPoint> resultCorePoints = kMeansCluster.getInitIndividual();
        //TODO 保存Hbase classier
        if (results != null && results.length > 0) {
            for (List<IndividualCommonPoint> individuals : results) {
                classifierHao.addAClassifier(individuals);
            }
        }
        classifierCorePointHao.addToHBase(resultCorePoints);
        Long endTimeMills = System.currentTimeMillis();
        logger.info("doKMeansCluser 结束 时间：" + DateUtil.formatDate(new Date(endTimeMills)) + "：花费时间：" + (endTimeMills - startMills)/1000 + "秒");
    }

    /**
     *
     * 清洗hdfs数据，存入hbase
     * @param resultUri
     */
    public void washLog(String resultUri) {
        Long startMills = System.currentTimeMillis();
        logger.info("washLog 开始：时间：" + startMills);
        HdfsResultCarryer hdfsResultCarryer = new HdfsResultCarryer(uri, resultUri, hbaseApi);
        hdfsResultCarryer.doCarry();
        logger.info("wasLog 结束：花费时间：" + (System.currentTimeMillis() - startMills) / 1000 + "秒");
    }

    public void doRcmdCoreTask(String resultUri) {
        washLog(resultUri);
        List<IndividualCommonPoint> individualInterestPoints = invidualInterestPointHao.getAllIndivialInterestPoints();
        doKMeansCluser(individualInterestPoints);
        //计算没个分类下各个IP交叉距离度，保存
        ipToIpIndividual();
    }

    public void findAndSort(String ip) {
        //ipToIpDis 里一个个进行分析
        //公式   R(A,x) = R(B,x)/(D(B,A) + 1)
        //之后倒排 大的在前，小的在后
       // IndividualCommonPoint ipToIpDis = ipToIpDisHao.getByIP(ip);
        IndividualCommonPoint ipToIpDis = ipToIpDisRao.getByIP(ip);
        if (ipToIpDis == null) {
            return ;
        }
        List<ColumnGoal> columnGoals = ipToIpDis.getColumnGoals();
        if (ipToIpDis != null && ipToIpDis.size() > 0) {
            //距离顺排 小的在前
            Collections.sort(columnGoals, new Comparator<ColumnGoal>() {
                @Override
                public int compare(ColumnGoal o1, ColumnGoal o2) {
                    double compareResult = o1.getGoal() - o2.getGoal();
                    return compareResult < 0 ? -1 : (compareResult > 0 ? 1 : 0);
                }
            });
            IndividualCommonPoint rAPoint = invidualInterestPointHao.getByIP(ip);
            List<ColumnGoal> raGoals = rAPoint.getColumnGoals();
            IndividualCommonPoint raxPoint = new IndividualCommonPoint();
            raxPoint.setIp(ip);
            for (ColumnGoal columnGoal : columnGoals) {
                Set<String> totalXR = new HashSet<>();
                double dBA = columnGoal.getGoal();
                String bIp = columnGoal.getColumn();
                IndividualCommonPoint rBPoint = invidualInterestPointHao.getByIP(bIp);
                //去除AB重复的项
                totalXR.addAll(rBPoint.keySet());
                totalXR.removeAll(rAPoint.keySet());
                for (String column : totalXR) {
                    double rbx = rBPoint.get(column);
                    double rax = rbx/(dBA + 1);
                    double remainRx = raxPoint.get(column);
                    raxPoint.addColumnGoal(new ColumnGoal(column, remainRx + rax));
                }
            }
            recmdResultHao.addToHbase(raxPoint);
        }
    }

    public void ipToIpIndividual() {
        /**
         * 1:全量get出分类信息
         * 2：遍历分类信息中的IP 与分类下其他IP进行交叉计算距离度
         */
        Long startMills = System.currentTimeMillis();
        logger.info("iptoIp 开始：时间：" + System.currentTimeMillis());
        //分类表
        List<IndividualCommonPoint> classifierPoints = classifierHao.queryAll();
        if (classifierPoints != null && classifierPoints.size() > 0) {
            logger.info("总共 分类数：" + classifierPoints.size());
            int index = 0;
            for (IndividualCommonPoint classifierPoint : classifierPoints) {
                logger.info("/*****************开始第" + (index + 1) + "个分类下的 IP交叉 *********************/");
                logger.info("总IP数：" + classifierPoint.getColumnGoals().size());
                Long classStartMills = System.currentTimeMillis();
                logger.info("开始时间 ：" + new Date(classStartMills));
                //这个分类下所有IP内容
                List<ColumnGoal> classifierColumnGoals = classifierPoint.getColumnGoals();
                if (classifierColumnGoals != null && classifierColumnGoals.size() > 0) {
                    for (ColumnGoal columnGoalSrc : classifierColumnGoals) {
                        if (columnGoalSrc.getColumn() == null || columnGoalSrc.getColumn().equals("null")) {
                            continue;
                        }
                        //对比的源
                        IndividualCommonPoint srcInterestPoint = invidualInterestPointHao.getByIP(columnGoalSrc.getColumn());
                        IndividualCommonPoint ipToIpIndividual = new IndividualCommonPoint();
                        if (srcInterestPoint == null || srcInterestPoint.getIp() == null) {
                            continue;
                        }

                        List<ColumnGoal> desColumnGoals = classifierHao.queryNearIps(columnGoalSrc.getColumn(), 50);
                        if (desColumnGoals == null || desColumnGoals.size() < 1) {
                            continue;
                        }
                        for (ColumnGoal columnGoalDes : desColumnGoals) {
                            if (!columnGoalSrc.equals(columnGoalDes)) {
                                //ip为null不进行交叉
                                if (columnGoalDes.getColumn() == null || columnGoalDes.getColumn().equals("null")) {
                                    continue;
                                }
                                ipToIpIndividual.setIp(columnGoalSrc.getColumn());
                                IndividualCommonPoint desPoint = invidualInterestPointHao.getByIP(columnGoalDes.getColumn());
                                Double ipToIpDis = KMeansUtils.distanceValue(srcInterestPoint, desPoint);
                                ipToIpIndividual.addColumnGoal(new ColumnGoal(desPoint.getIp(), ipToIpDis));
                            }
                        }
                        if (ipToIpIndividual != null && ipToIpIndividual.getColumnGoals() != null && ipToIpIndividual.size() > 0) {
                            //ipToIpDisHao.addToHbase(ipToIpIndividual);
                            ipToIpDisRao.addToHbase(ipToIpIndividual);
                        }
                    }
                }
                logger.info("耗时：" + (System.currentTimeMillis() - classStartMills)/1000 + "秒");
                logger.info("/******************第" + (index + 1) + "个分类计算结束*****************/");
                index++;
            }
        }
        logger.info("iptoIp 结束：花费时间：" + (System.currentTimeMillis() - startMills) / 1000 + "秒");
    }

    /**
     * 获取推荐列表
     * @param ip
     * @return
     */
    public List<ColumnGoal> getRecmdInfo(String ip) {
        List<ColumnGoal> resultGoals = recmdResultHao.getByIP(ip);
        if (resultGoals == null) {
            this.findAndSort(ip);
            resultGoals = recmdResultHao.getByIP(ip);
        }
        if (resultGoals != null && resultGoals.size() > 0) {
            Collections.sort(resultGoals, new Comparator<ColumnGoal>() {
                @Override
                public int compare(ColumnGoal o1, ColumnGoal o2) {
                    double compareResult = o1.getGoal() - o2.getGoal();
                    return compareResult < 0 ? 1 : (compareResult > 0 ? -1 : 0);
                }
            });
            if (resultGoals.size() > 20) {
                resultGoals = resultGoals.subList(0, 20);
            }
        }
        return resultGoals;
    }

    public static void mai1(String[] args) {
        RecmdCoreService recmdCoreService = new RecmdCoreService();
        //recmdCoreService.doRcmdCoreTask("hdfs://10.5.117.109:9000/spark/job/result/20160919.result");
        Long startTime = System.currentTimeMillis();
        System.out.println("开始 进行聚类时间：" + startTime);
        List<IndividualCommonPoint> individualInterestPoints = recmdCoreService.invidualInterestPointHao.getAllIndivialInterestPoints();
        recmdCoreService.doKMeansCluser(individualInterestPoints);
        Long entTime = System.currentTimeMillis();
        System.out.println("结束 时间：" + entTime + "耗时：" + (entTime-startTime)/1000 + "秒");
    }

    public static void main(String[] args) {
        RecmdCoreService recmdCoreService = new RecmdCoreService();
        recmdCoreService.doRcmdCoreTask("hdfs://10.5.117.109:9000/spark/job/result/20160918.result");
    }
}
